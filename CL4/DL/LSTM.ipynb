{"cells":[{"cell_type":"markdown","id":"e0520895","metadata":{"id":"e0520895"},"source":["# Design RNN or its variant including LSTM or GRU\n","a) Select a suitable time series dataset. Example – predict sentiments based on product reviews\n","\n","b) Apply for prediction"]},{"cell_type":"code","execution_count":null,"id":"54e09870","metadata":{"scrolled":true,"id":"54e09870"},"outputs":[],"source":["import numpy as np\n","from tensorflow.keras.datasets import imdb\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","# Load data (only top 10,000 words)\n","(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n","\n","# Pad sequences to have same input length\n","x_train = pad_sequences(x_train, maxlen=200)\n","x_test = pad_sequences(x_test, maxlen=200)"]},{"cell_type":"markdown","id":"001688fc","metadata":{"id":"001688fc"},"source":["#### from tensorflow.keras.datasets import imdb\n","#### from tensorflow.keras.preprocessing.sequence import pad_sequences\n","    imdb: Built-in movie reviews dataset (sentiment labeled).\n","\n","    pad_sequences: Helps make all input sequences the same length (needed for LSTM).\n","\n","#### Loads the dataset:\n","\n","    x_train: list of reviews (as sequences of integers)\n","\n","    y_train: corresponding labels (1 = positive, 0 = negative)\n","\n","    num_words=10000: only use the top 10,000 most common words to limit vocabulary size.\n","\n","#### x_train = pad_sequences(x_train, maxlen=200)\n","#### x_test = pad_sequences(x_test, maxlen=200)\n","\n","    Ensures every review has exactly 200 tokens.\n","\n","    Shorter sequences are padded with zeros at the beginning.\n","\n","    Longer ones are trimmed from the start.\n","\n","    This creates a uniform input shape of (samples, 200) needed for neural networks."]},{"cell_type":"code","execution_count":null,"id":"046bda9c","metadata":{"id":"046bda9c"},"outputs":[],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense\n","\n","model = Sequential()\n","model.add(Embedding(input_dim=10000, output_dim=128, input_length=200))\n","model.add(LSTM(units=128))\n","model.add(Dense(1, activation='sigmoid'))  # Binary classification\n","\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"]},{"cell_type":"markdown","id":"f69616c4","metadata":{"id":"f69616c4"},"source":["### Import Keras model architecture tools.\n","\n","    Embedding: Turns word indexes into vectors.\n","\n","    LSTM: Long Short-Term Memory layer (remembers sequences).\n","\n","    Dense: Standard neural net layer.\n","### Embedding Layer: model.add(Embedding(input_dim=10000, output_dim=128, input_length=200))\n","\n","    input_dim=10000: Total words in vocab.\n","\n","    output_dim=128: Each word will be converted to a vector of 128 values.\n","\n","    input_length=200: Input reviews are 200 tokens long (after padding).\n","\n","    Result: Converts shape from (batch_size, 200) → (batch_size, 200, 128)\n","### model.add(LSTM(units=128))\n","LSTM layer processes the sequence of word vectors:\n","\n","    units=128: Memory size of LSTM\n","\n","Output shape becomes (batch_size, 128) after summarizing time-series info.\n","### model.add(Dense(1, activation='sigmoid'))\n","\n","    Outputs 1 neuron → predicts probability between 0 and 1.\n","\n","    sigmoid: squashes output into range (0 to 1).\n","### Compile model:\n","\n","    adam: Adaptive optimizer, adjusts learning rate.\n","\n","    binary_crossentropy: Used for binary classification (0 or 1).\n","\n","    metrics=['accuracy']: Tracks how many predictions were correct."]},{"cell_type":"code","execution_count":null,"id":"ebbd0b25","metadata":{"id":"ebbd0b25","outputId":"171a26ac-a23d-413d-8e80-bbb2b8007fdd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/3\n","\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 170ms/step - accuracy: 0.7396 - loss: 0.5123 - val_accuracy: 0.8401 - val_loss: 0.3822\n","Epoch 2/3\n","\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 171ms/step - accuracy: 0.8944 - loss: 0.2697 - val_accuracy: 0.7862 - val_loss: 0.4460\n","Epoch 3/3\n","\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 170ms/step - accuracy: 0.9210 - loss: 0.2085 - val_accuracy: 0.8552 - val_loss: 0.3704\n"]}],"source":["history = model.fit(x_train, y_train,\n","                    epochs=3,\n","                    batch_size=64,\n","                    validation_data=(x_test, y_test))"]},{"cell_type":"code","execution_count":null,"id":"c0643179","metadata":{"id":"c0643179","outputId":"b84c93b2-e6aa-4f85-bca9-29ce1ed0eb2c"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 26ms/step - accuracy: 0.8542 - loss: 0.3716\n","Test Loss 37.037211656570435\n","Test Accuracy: 85.51999926567078\n"]}],"source":["# Evaluate accuracy on test set\n","test_loss, test_acc = model.evaluate(x_test, y_test)\n","print(\"Test Loss\", test_loss*100)\n","print(\"Test Accuracy:\", test_acc*100)"]},{"cell_type":"code","execution_count":null,"id":"0175eb5d","metadata":{"id":"0175eb5d","outputId":"b3d92e93-27aa-40bb-ebfd-4cb6ea51931d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sample Review (Text):\n","psychological ? it's very interesting that robert altman directed this considering the style and structure of his other films still the trademark altman audio style is evident here and there i think what really makes this film work is the brilliant performance by sandy dennis it's definitely one of her darker characters but she plays it so perfectly and convincingly that it's scary michael burns does a good job as the mute young man regular altman player michael murphy has a small part the ? moody set fits the content of the story very well in short this movie is a powerful study of loneliness sexual ? and desperation be patient ? up the atmosphere and pay attention to the wonderfully written script br br i praise robert altman this is one of his many films that deals with unconventional fascinating subject matter this film is disturbing but it's sincere and it's sure to ? a strong emotional response from the viewer if you want to see an unusual film some might even say bizarre this is worth the time br br unfortunately it's very difficult to find in video stores you may have to buy it off the internet\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","[[0.9910498]]\n","\n","Predicted Sentiment: Positive\n"]}],"source":["# Load word index and reverse it\n","word_index = imdb.get_word_index()\n","reverse_word_index = {value: key for (key, value) in word_index.items()}\n","\n","# Decode the review (subtract 3 for actual words)\n","decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in x_test[1]])\n","\n","# Print the review text\n","print(\"Sample Review (Text):\")\n","print(decoded_review)\n","\n","# Predict\n","sample = x_test[1].reshape(1, 200)\n","prediction = model.predict(sample)\n","print(prediction)\n","\n","print(\"\\nPredicted Sentiment:\", \"Positive\" if prediction[0][0] > 0.5 else \"Negative\")"]},{"cell_type":"markdown","id":"ea7a07cf","metadata":{"id":"ea7a07cf"},"source":["### ❗ i - 3 is used because:\n","\n","Keras reserves:\n","\n","0 = padding\n","\n","1 = start of sequence\n","\n","2 = unknown word\n","\n","3 and above = actual word indexes"]},{"cell_type":"code","execution_count":null,"id":"883c4a8a","metadata":{"id":"883c4a8a"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}